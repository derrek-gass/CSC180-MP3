{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-BeOChlfOfY"
   },
   "source": [
    "## Mini-Project 3:  Computer Vision using GPU and Transfer Learning\n",
    "\n",
    "\n",
    "#### CSC 180 Intelligent Systems (Fall 2019)\n",
    "\n",
    "#### Dr. Haiquan Chen, California State University, Sacramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rENMVFFibA3H"
   },
   "outputs": [],
   "source": [
    "# Derrek Gass (219615449)\n",
    "# Alexander Lee (212490812)\n",
    "# CSC180 - Intelligent Systems\n",
    "# Mini-Project 3\n",
    "# 10-25-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LlFpkRqpfOfa"
   },
   "source": [
    "\n",
    "## Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOddo2bbfOfb"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, collections.Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qU8FIYWRVXM1"
   },
   "source": [
    "## Switch and Verify GPU\n",
    "\n",
    "### To enable GPU backend for your notebook. Runtime->Change runtime type->Hardware Accelerator->GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1s9pBa09U_zJ",
    "outputId": "08ad12d5-a782-4129-92b2-7ca8650d9034"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFpkSEEDbTag"
   },
   "source": [
    "### If the above code output '/device:GPU:0',  you have switched to GPU successfully and you are ready to go. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kv39g9StfOff"
   },
   "source": [
    "## Part I:   Image classification without transfer learning\n",
    "\n",
    "https://www.kaggle.com/c/cifar-10/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "0495-SoMfOfg",
    "outputId": "796fa732-0231-46c0-8827-59ca69303a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 114s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#  Load cifar-10 data and split it to training and test\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# The data split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DWyVv_efOfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Check data shape\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZSaas31fOfo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfDjuB-_fOfr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a9b8349c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's print out one image in the training set\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgRiH7S4fOfu"
   },
   "outputs": [],
   "source": [
    "# Convert y_train from 2D to 1D    \n",
    "\n",
    "y_train = y_train.reshape(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MfVmrQ-fOfx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check y shape\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "\n",
    "# expected output:  (50000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWvawslufOfz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]\n",
    "\n",
    "# expected output:  9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcrolrznfOf2"
   },
   "outputs": [],
   "source": [
    "# Convert y_test from 2D to 1D \n",
    "\n",
    "y_test = y_test.reshape(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iT3IYTNqfOf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "\n",
    "# expected output: (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-lWtPlHfOf9"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to one hot format\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFzHf8QefOgC"
   },
   "outputs": [],
   "source": [
    "# Convert data from int to float and normalize it\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXXjBVW1lDt1"
   },
   "source": [
    "### 10 pts: Write your code in the cell below to create a CNN model which contains the following types of operations (layers):   \n",
    "\n",
    "- Conv2D\n",
    "- Activation\n",
    "- MaxPooling2D\n",
    "- Flatten\n",
    "- Dropout\n",
    "- Dense\n",
    "\n",
    "\n",
    "### You are also encouraged to create multiple models with different numbers of neurons and layers for performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grVEwQfQfOgE"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FekC4kgffOgG"
   },
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVNwHr_AmKJi"
   },
   "source": [
    "### 10 pts: Write your code in the cell below for compile, earlystopping and fit. Notice that you should use earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUxCqaaZfOgI"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xigd26XOoU-F"
   },
   "source": [
    "### 10 pts:  Write your code in the cell below to print out the Precision, Recall,  F1 score, and classification_*report*\n",
    "\n",
    "### Include your findings in the project report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_92T0bsfOgQ"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgBnw9dRfOgS"
   },
   "source": [
    "\n",
    "\n",
    "## Part II:   With Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9rvtqrsfOgT"
   },
   "outputs": [],
   "source": [
    "# We load data again.   The data split between train and test sets:\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGSxqVVypDiX"
   },
   "source": [
    "### Here we would like to use one pre-trained model called VGG16.   For more details on VGG16, please go to https://neurohive.io/en/popular-networks/vgg16/\n",
    "\n",
    "\n",
    "- VGG16 supports down to 48x48 images as an input. However, the resolution of our images is too low, which is (32, 32) so we need to increase the resolution.   This is called upsampling. \n",
    "\n",
    "- The following cells show you how we can do upsampling for each image to increase its resolution from 32x32 to 64x64 by using the function resize(), which is provided by scikit-image library (https://scikit-image.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWwBKsh-fOgX"
   },
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "\n",
    "new_x_train = []\n",
    "\n",
    "for image in x_train:\n",
    "  newImage = skimage.transform.resize(image, (64, 64))      # note that resize() also normalizes your image\n",
    "  new_x_train.append(newImage)\n",
    "  \n",
    "\n",
    "# this code may take about 3 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaQ8rcNDfOga"
   },
   "outputs": [],
   "source": [
    "new_x_train = np.asarray(new_x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jm6hMVrqfOgc"
   },
   "outputs": [],
   "source": [
    "new_x_train.shape\n",
    "\n",
    "\n",
    "# expected output:  (50000, 64, 64, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s0-oaKDfOgf"
   },
   "outputs": [],
   "source": [
    "new_x_test = []\n",
    "\n",
    "for image in x_test:\n",
    "  newImage = skimage.transform.resize(image, (64, 64))\n",
    "  new_x_test.append(newImage)\n",
    "\n",
    "\n",
    "  # this code may take about 2 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwYHdSo0fOgh"
   },
   "outputs": [],
   "source": [
    "new_x_test = np.asarray(new_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmw0t9UzfOgk"
   },
   "outputs": [],
   "source": [
    "new_x_test.shape\n",
    "\n",
    "\n",
    "# expected output:  (10000, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPjFo2oyqlGO"
   },
   "source": [
    "### 10 pts: Write your code in the cell below to do the following:\n",
    "\n",
    "- First convert y_train and y_test from 2D to 1D by using reshape() function \n",
    "- Next apply one-hot encoding to y_train and y_test by using tf.keras.utils.to_categorical() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQuVaf2pkRdr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_pLuCNjqvbf"
   },
   "outputs": [],
   "source": [
    "# double check shape\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# expected output:  (50000, 10)\n",
    "# expected output:  (10000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-bzRNdjfOgy"
   },
   "source": [
    "### 5 pts: Now let's load the pre-trained VGG16 model.  Write your code in the cell below to add each layer in VGG16 (excluding the top layers) to your new model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HLwE00VfOgz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))   #  first hidden layer\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "  \n",
    "# write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print out the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ki8D32hrl3E"
   },
   "source": [
    "### 5 pts: Write your code in the cell below to freeze the weights in each layer in the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_oqboGwfOg1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YArrSsS4rt_t"
   },
   "source": [
    "### 5 pts:  Write your code in the cell below to add some \"Dense\" layers as top layers.\n",
    "\n",
    "- Donot forget the output layer\n",
    "- Choose the right activation fucntion for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fphbz0FhfOg3"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Add some \"Dense\" layers here, including output layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDOG92fcr1m8"
   },
   "source": [
    "### 5 pts:  Write your code in the cell below for compile and fit.   Notice that you should use earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWrWTc2JfOg6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# since we use GPU, the training time for each epoch for the transferred model is about 60 seconds.  Let it run for a few epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ps2CZ8Xwrz_a"
   },
   "source": [
    "### 5 pts:  Write your code in the cell below to print out the Precision, Recall, F1 score, and classification_report\n",
    "\n",
    "### Include your findings in the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMRuLfS3fOg8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PkatwrTod_ii"
   },
   "source": [
    "### 5 pts: Write your code in the cell below to show 3-5 images in the test set as well as their true labels and their labels predicted by your created model\n",
    "\n",
    "### Include your findings in the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoRepUWbd_ii"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "CSC180_Transfer_learning_project_on_cifar_10_(canvas_version).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
